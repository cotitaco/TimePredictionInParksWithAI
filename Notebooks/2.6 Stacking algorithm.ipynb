{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f5e743",
   "metadata": {},
   "source": [
    "# Stacking Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab859ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81335ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_oHe = pd.read_csv('HP_OHE_3class.csv')\n",
    "hp_oHe.drop(hp_oHe.tail(17).index,inplace=True) \n",
    "hp_oHe = hp_oHe.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "hp_ME = pd.read_csv(\"harryPotterClean.csv\")\n",
    "hp_ME.drop(hp_ME.tail(17).index,inplace=True) \n",
    "hp_ME = hp_ME.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "hp_OE = pd.read_csv(\"harryPotterCleanOE.csv\")\n",
    "hp_OE.drop(hp_OE.tail(17).index,inplace=True) \n",
    "hp_OE = hp_OE.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1573256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXandY(df):\n",
    "    df.drop(df.tail(20).index,inplace=True) \n",
    "    x = df.drop(['HP_Forbidden_clean'],axis=1)\n",
    "    y = df.HP_Forbidden_clean\n",
    "    return(x,y)\n",
    "\n",
    "def trainTest(x,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, shuffle=True)\n",
    "    return(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Function to perform oversampling\n",
    "def overSampling(X_train, y_train, y_test, method):\n",
    "    X_train_os, y_train_os= method.fit_resample(X_train, y_train)\n",
    "    # Check the number of records after over sampling\n",
    "    #print(sorted(Counter(y_train_os).items())) \n",
    "    return(X_train_os, y_train_os)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "\n",
    "def testModel(df,var_order,n_vars,n_loops,method):\n",
    "    highest = 0\n",
    "    for j in tqdm(range(1,n_vars)):\n",
    "        #split our dataframe into X and Y\n",
    "        x,y=getXandY(df)\n",
    "        #create the lists to store metrics\n",
    "        acc = []\n",
    "        rec = []\n",
    "        preci = []\n",
    "        f1 = []\n",
    "        for i in range(n_loops):\n",
    "            #split the dataFrame into test and train\n",
    "            X_train, X_test, y_train, y_test = trainTest(x,y)\n",
    "            #Oversample the train dataset with SMOTE\n",
    "            X_train_os, y_train_os=overSampling(X_train, y_train, y_test, smote)\n",
    "            #define the variables order \n",
    "            X_train_os_r = X_train_os[var_order]\n",
    "            X_test_r = X_test[var_order]\n",
    "            df1= X_train_os_r.iloc[:, 0:j] #use only part of the variables\n",
    "            \n",
    "            #create and train decision trees\n",
    "            rnd_clf = RandomForestClassifier(n_jobs=-1)\n",
    "            rnd_clf.fit(df1, y_train_os)\n",
    "        \n",
    "            y_pred=rnd_clf.predict(X_test_r.iloc[:, 0:j])\n",
    "            ac=metrics.accuracy_score(y_test, y_pred)\n",
    "            acc.append(ac)\n",
    "            p=metrics.precision_score(y_test, y_pred,average='macro')\n",
    "            preci.append(p)\n",
    "            r=metrics.recall_score(y_test, y_pred,average='macro')\n",
    "            rec.append(r)\n",
    "            f=metrics.f1_score(y_test, y_pred, average='macro')\n",
    "            f1.append(f)\n",
    "        print(df1.columns)\n",
    "        print(\"For {} features: \\n Accuracy: {} \\n Precision: {} \\n Recall: {} \\n F1 score: {}\".format(\n",
    "        j,mean(acc),mean(preci),mean(rec),mean(f1)))\n",
    "        \n",
    "        if mean(acc)>highest:\n",
    "            highest = mean(acc)\n",
    "            best = \"best accuracy = {}, with {} features, with {}\".format(mean(acc),j,method)\n",
    "        print(best)\n",
    "        #print(classification_report(y_test, y_pred))\n",
    "    print(best)\n",
    "        \n",
    "def analizeDF(df,order,n_vars,n_loops):\n",
    "    for i in range(len(order)):\n",
    "        print('------------------------- Analyzing method {} -------------------------'.format(method[i]))\n",
    "        print('The variable order is: \\n {}'.format(order[i]))\n",
    "        testModel(df,order[i],n_vars,n_loops,method[i])\n",
    "        print('\\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "026ab465",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('abc', AdaBoostClassifier()),\n",
    "    ('svm', SVC())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5d448",
   "metadata": {},
   "source": [
    "Test 1 Final Estimator with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b652bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=getXandY(hp_oHe)\n",
    "#split the dataFrame into test and train\n",
    "X_train, X_test, y_train, y_test = trainTest(x,y)\n",
    "#Oversample the train dataset with SMOTE\n",
    "X_train_os, y_train_os=overSampling(X_train, y_train, y_test, smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0b6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_clf = StackingClassifier(\n",
    "    estimators=esiitimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69c4971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier()),\n",
       "                               ('dt', DecisionTreeClassifier()),\n",
       "                               ('gbc', GradientBoostingClassifier()),\n",
       "                               ('abc', AdaBoostClassifier()), ('svm', SVC())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk_clf.fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "519a336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87481434330575\n"
     ]
    }
   ],
   "source": [
    "y_pred=stk_clf.predict(X_test)\n",
    "ac=metrics.accuracy_score(y_test, y_pred)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3bc2d",
   "metadata": {},
   "source": [
    "Test 2 Final Estimator with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83c4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testStaking(final):\n",
    "    stk_clf = StackingClassifier(estimators=estimators, final_estimator=final)\n",
    "    stk_clf.fit(X_train_os, y_train_os)\n",
    "    y_pred=stk_clf.predict(X_test)\n",
    "    ac=metrics.accuracy_score(y_test, y_pred)\n",
    "    print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39369210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8754508805431784\n"
     ]
    }
   ],
   "source": [
    "testStaking(SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169c124",
   "metadata": {},
   "source": [
    "Test 3 Final Estimator with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2d26b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8735412688308932\n"
     ]
    }
   ],
   "source": [
    "testStaking(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef37277",
   "metadata": {},
   "source": [
    "Test 4 Final Estimator with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5132826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8357733927434755\n"
     ]
    }
   ],
   "source": [
    "testStaking(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf46ba3",
   "metadata": {},
   "source": [
    "Test 5 Final Estimator with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40561cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697220454063229\n"
     ]
    }
   ],
   "source": [
    "testStaking(AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbf311",
   "metadata": {},
   "source": [
    "Test 6 Final Estimator with GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6128c806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87481434330575\n"
     ]
    }
   ],
   "source": [
    "testStaking(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384a276",
   "metadata": {},
   "source": [
    "Tuning hyper parameters of each estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025e504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(max_depth=50, min_samples_leaf=1, \n",
    "                                  min_samples_split=2, n_estimators=200)),\n",
    "    ('dt', DecisionTreeClassifier(criterion='entropy', splitter='random',  max_depth=500, min_samples_split=2)),\n",
    "    ('gbc', GradientBoostingClassifier(n_estimators=500, learning_rate=1, max_depth=None)),\n",
    "    ('abc', AdaBoostClassifier(RandomForestClassifier(), n_estimators=100, learning_rate=0.9)),\n",
    "    ('svm', SVC(kernel=\"poly\", degree=7, coef0=1, C=1000))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "testStaking(SVC(kernel=\"poly\", degree=7, coef0=1, C=1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
